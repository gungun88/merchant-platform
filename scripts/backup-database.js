/**
 * ğŸ”’ Database Backup Script (æ•°æ®åº“å¤‡ä»½è„šæœ¬)
 *
 * åŠŸèƒ½ï¼š
 * - å¯¼å‡ºæ‰€æœ‰æ•°æ®è¡¨ä¸ºJSONæ ¼å¼
 * - æŒ‰æ—¥æœŸç»„ç»‡å¤‡ä»½æ–‡ä»¶
 * - è‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™æœ€è¿‘30å¤©ï¼‰
 * - æ”¯æŒå¢é‡å¤‡ä»½å’Œå®Œæ•´å¤‡ä»½
 *
 * ä½¿ç”¨æ–¹æ³•ï¼š
 * node scripts/backup-database.js              # å®Œæ•´å¤‡ä»½
 * node scripts/backup-database.js --tables merchants,profiles  # æŒ‡å®šè¡¨å¤‡ä»½
 */

const { createClient } = require('@supabase/supabase-js')
const fs = require('fs')
const path = require('path')

// é…ç½®
const SUPABASE_URL = process.env.NEXT_PUBLIC_SUPABASE_URL
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY // éœ€è¦Service Roleå¯†é’¥
const BACKUP_DIR = path.join(__dirname, '..', 'backups')
const BACKUP_RETENTION_DAYS = 30 // ä¿ç•™30å¤©çš„å¤‡ä»½

// éœ€è¦å¤‡ä»½çš„è¡¨
const TABLES_TO_BACKUP = [
  'profiles',
  'merchants',
  'merchant_tops',
  'merchant_views',
  'transactions',
  'rewards',
  'invitations',
  'notifications',
  'user_notifications',
]

// éªŒè¯ç¯å¢ƒå˜é‡
if (!SUPABASE_URL || !SUPABASE_SERVICE_KEY) {
  console.error('âŒ é”™è¯¯: ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡')
  console.error('éœ€è¦è®¾ç½®: NEXT_PUBLIC_SUPABASE_URL å’Œ SUPABASE_SERVICE_ROLE_KEY')
  console.error('\nğŸ’¡ æç¤º: Service Role Keyå¯ä»¥åœ¨Supabase Dashboard â†’ Settings â†’ APIä¸­æ‰¾åˆ°')
  process.exit(1)
}

// åˆ›å»ºSupabaseå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨Service Roleä»¥ç»•è¿‡RLSï¼‰
const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY, {
  auth: {
    autoRefreshToken: false,
    persistSession: false
  }
})

/**
 * åˆ›å»ºå¤‡ä»½ç›®å½•
 */
function ensureBackupDir() {
  const timestamp = new Date().toISOString().split('T')[0] // YYYY-MM-DD
  const backupPath = path.join(BACKUP_DIR, timestamp)

  if (!fs.existsSync(BACKUP_DIR)) {
    fs.mkdirSync(BACKUP_DIR, { recursive: true })
  }

  if (!fs.existsSync(backupPath)) {
    fs.mkdirSync(backupPath, { recursive: true })
  }

  return backupPath
}

/**
 * å¤‡ä»½å•ä¸ªè¡¨
 */
async function backupTable(tableName, backupPath) {
  try {
    console.log(`ğŸ“¥ æ­£åœ¨å¤‡ä»½è¡¨: ${tableName}...`)

    // åˆ†é¡µè·å–æ‰€æœ‰æ•°æ®ï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
    let allData = []
    let page = 0
    const pageSize = 1000

    while (true) {
      const { data, error, count } = await supabase
        .from(tableName)
        .select('*', { count: 'exact' })
        .range(page * pageSize, (page + 1) * pageSize - 1)

      if (error) {
        console.error(`   âŒ å¤‡ä»½å¤±è´¥: ${error.message}`)
        return { success: false, count: 0 }
      }

      if (data && data.length > 0) {
        allData = allData.concat(data)
      }

      // å¦‚æœæ²¡æœ‰æ›´å¤šæ•°æ®ï¼Œé€€å‡ºå¾ªç¯
      if (!data || data.length < pageSize) {
        break
      }

      page++
    }

    // å†™å…¥JSONæ–‡ä»¶
    const filename = path.join(backupPath, `${tableName}.json`)
    fs.writeFileSync(filename, JSON.stringify(allData, null, 2), 'utf-8')

    console.log(`   âœ… æˆåŠŸå¤‡ä»½ ${allData.length} æ¡è®°å½•`)
    return { success: true, count: allData.length }

  } catch (error) {
    console.error(`   âŒ å¤‡ä»½å¼‚å¸¸: ${error.message}`)
    return { success: false, count: 0 }
  }
}

/**
 * å¤‡ä»½æ•°æ®åº“å…ƒæ•°æ®ï¼ˆè¡¨ç»“æ„ã€ç´¢å¼•ç­‰ï¼‰
 */
async function backupMetadata(backupPath) {
  try {
    console.log(`ğŸ“¥ æ­£åœ¨å¤‡ä»½æ•°æ®åº“å…ƒæ•°æ®...`)

    // è·å–æ‰€æœ‰è¡¨çš„ä¿¡æ¯
    const { data: tables, error } = await supabase.rpc('get_table_info')

    if (error) {
      // å¦‚æœå‡½æ•°ä¸å­˜åœ¨ï¼Œè®°å½•è­¦å‘Šä½†ä¸ä¸­æ–­å¤‡ä»½
      console.warn(`   âš ï¸  æ— æ³•è·å–è¡¨ä¿¡æ¯: ${error.message}`)
      console.warn(`   æç¤º: éœ€è¦åœ¨æ•°æ®åº“ä¸­åˆ›å»º get_table_info() å‡½æ•°`)
      return { success: false }
    }

    const filename = path.join(backupPath, '_metadata.json')
    fs.writeFileSync(filename, JSON.stringify(tables, null, 2), 'utf-8')

    console.log(`   âœ… å…ƒæ•°æ®å¤‡ä»½å®Œæˆ`)
    return { success: true }

  } catch (error) {
    console.warn(`   âš ï¸  å…ƒæ•°æ®å¤‡ä»½å¤±è´¥: ${error.message}`)
    return { success: false }
  }
}

/**
 * æ¸…ç†æ—§å¤‡ä»½
 */
function cleanOldBackups() {
  try {
    console.log(`ğŸ§¹ æ­£åœ¨æ¸…ç†æ—§å¤‡ä»½...`)

    if (!fs.existsSync(BACKUP_DIR)) {
      return
    }

    const now = new Date()
    const dirs = fs.readdirSync(BACKUP_DIR)
    let deletedCount = 0

    dirs.forEach(dir => {
      const dirPath = path.join(BACKUP_DIR, dir)
      const stat = fs.statSync(dirPath)

      if (stat.isDirectory()) {
        const dirDate = new Date(dir) // å‡è®¾ç›®å½•åæ˜¯æ—¥æœŸæ ¼å¼
        const ageInDays = (now - dirDate) / (1000 * 60 * 60 * 24)

        if (ageInDays > BACKUP_RETENTION_DAYS) {
          fs.rmSync(dirPath, { recursive: true })
          deletedCount++
          console.log(`   ğŸ—‘ï¸  åˆ é™¤æ—§å¤‡ä»½: ${dir}`)
        }
      }
    })

    if (deletedCount === 0) {
      console.log(`   âœ… æ— éœ€æ¸…ç†æ—§å¤‡ä»½`)
    } else {
      console.log(`   âœ… æ¸…ç†äº† ${deletedCount} ä¸ªæ—§å¤‡ä»½`)
    }

  } catch (error) {
    console.warn(`   âš ï¸  æ¸…ç†å¤±è´¥: ${error.message}`)
  }
}

/**
 * åˆ›å»ºå¤‡ä»½æ‘˜è¦
 */
function createBackupSummary(backupPath, results) {
  const summary = {
    timestamp: new Date().toISOString(),
    tables: results.tables,
    totalRecords: results.tables.reduce((sum, t) => sum + t.count, 0),
    success: results.tables.every(t => t.success),
    metadata: results.metadata,
  }

  const filename = path.join(backupPath, '_summary.json')
  fs.writeFileSync(filename, JSON.stringify(summary, null, 2), 'utf-8')

  return summary
}

/**
 * ä¸»å¤‡ä»½å‡½æ•°
 */
async function performBackup(tablesToBackup = TABLES_TO_BACKUP) {
  console.log('ğŸš€ å¼€å§‹æ•°æ®åº“å¤‡ä»½...\n')
  console.log(`ğŸ“ Supabase URL: ${SUPABASE_URL}`)
  console.log(`ğŸ“ å¤‡ä»½ç›®å½•: ${BACKUP_DIR}`)
  console.log(`ğŸ“Š å¤‡ä»½è¡¨æ•°é‡: ${tablesToBackup.length}\n`)

  const startTime = Date.now()
  const backupPath = ensureBackupDir()

  // å¤‡ä»½æ‰€æœ‰è¡¨
  const results = {
    tables: [],
    metadata: null,
  }

  for (const tableName of tablesToBackup) {
    const result = await backupTable(tableName, backupPath)
    results.tables.push({
      table: tableName,
      success: result.success,
      count: result.count,
    })
  }

  // å¤‡ä»½å…ƒæ•°æ®
  results.metadata = await backupMetadata(backupPath)

  // åˆ›å»ºå¤‡ä»½æ‘˜è¦
  const summary = createBackupSummary(backupPath, results)

  // æ¸…ç†æ—§å¤‡ä»½
  cleanOldBackups()

  const duration = ((Date.now() - startTime) / 1000).toFixed(2)

  console.log('\n' + '='.repeat(60))
  console.log('ğŸ“Š å¤‡ä»½å®Œæˆæ‘˜è¦:')
  console.log('='.repeat(60))
  console.log(`âœ… æˆåŠŸå¤‡ä»½è¡¨: ${results.tables.filter(t => t.success).length}/${results.tables.length}`)
  console.log(`ğŸ“ˆ æ€»è®°å½•æ•°: ${summary.totalRecords}`)
  console.log(`â±ï¸  è€—æ—¶: ${duration}ç§’`)
  console.log(`ğŸ“ å¤‡ä»½ä½ç½®: ${backupPath}`)
  console.log('='.repeat(60))

  // æ˜¾ç¤ºå¤±è´¥çš„è¡¨
  const failedTables = results.tables.filter(t => !t.success)
  if (failedTables.length > 0) {
    console.log('\nâš ï¸  ä»¥ä¸‹è¡¨å¤‡ä»½å¤±è´¥:')
    failedTables.forEach(t => console.log(`   - ${t.table}`))
  }

  return summary.success
}

/**
 * è§£æå‘½ä»¤è¡Œå‚æ•°
 */
function parseArgs() {
  const args = process.argv.slice(2)
  let tablesToBackup = TABLES_TO_BACKUP

  for (let i = 0; i < args.length; i++) {
    if (args[i] === '--tables' && args[i + 1]) {
      tablesToBackup = args[i + 1].split(',').map(t => t.trim())
      break
    }
  }

  return { tablesToBackup }
}

// æ‰§è¡Œå¤‡ä»½
if (require.main === module) {
  const { tablesToBackup } = parseArgs()

  performBackup(tablesToBackup)
    .then(success => {
      process.exit(success ? 0 : 1)
    })
    .catch(error => {
      console.error('\nâŒ å¤‡ä»½è¿‡ç¨‹å‘ç”Ÿé”™è¯¯:', error)
      process.exit(1)
    })
}

module.exports = { performBackup }
